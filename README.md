## Описание проекта

Сопоставление или “мэтчинг” (англ. matching - соответствия) - одна из базовых задач машинного обучения, которая встречается в информационном поиске, компьютерном зрении, рекомендательных системах и др.

## [Посмотреть решение](matching.ipynb)

## Что надо сделать?

- разработать алгоритм, который для всех товаров из validation.csv предложит несколько вариантов наиболее похожих товаров из base;
- оценить качество алгоритма по метрике accuracy@5.

## Данные

- *base.csv* - анонимизированный набор товаров. Каждый товар представлен как уникальный id (0-base, 1-base, 2-base) и вектор признаков размерностью 72.
- *target.csv -* обучающий датасет. Каждая строчка - один товар, для которого известен уникальный id (0-query, 1-query, …) , вектор признаков И id товара из *base.csv*, который максимально похож на него (по мнению экспертов).
- *validation.csv* - датасет с товарами (уникальный id и вектор признаков), для которых надо найти наиболее близкие товары из *base.csv*
- *validation_answer.csv* - правильные ответы к предыдущему файлу.

## Итоги исследования
В проекте реализована комбинация алгоритма поиска ближайших соседей и машинного обучения (модуля Faiss). В данном случае количество класстеров было расчитано автоматически самим модулем, а количество кандидатов было выбрано мною в размере 10 и 100 штук.
Для масштабирования данных были выбраны также несколько кодировщиков со следующими результатами в поиске 10 кандидатов: 

| Scaler | Accuracy@10 | Time |
| ------ | ------ | ------ |
| StandardScaler | 69.789% | 12min 1s | 
| MinMaxScaler | 38.263% | 6min 12s | 
| AdjustedScaler | 58.330% | 6min 14s |

Самую хорошую метрику дал StandardScaler, посему и был выбран для поиска сотни соседей.
Для поиска самых оптимальных из кандидатов была выбрана модель CatBoostClassifier.  

Итоги исследования:

| Neighbors |	Accuracy |	Accuracy@5 | Time |
| ------ | ------ | ------ | ------ |
| 10	| 92% |	69% |	17min 7s |
| 100	| 89% |	79% |	16min 54s |

Важно: метрика для 100 кандидатов указана из расчета обученной модели на 1/10 имеющихся тренировочных данных. Предсказания так же получены только для 1/10 валидационной выборки. Расчеты для полных выборок будут точнее.
